{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ DHARTI S2DR3 Super-Resolution Pipeline\n",
        "\n",
        "**‚ö° ONE-CLICK AUTOMATED EXECUTION ‚ö°**\n",
        "\n",
        "This notebook automatically runs the complete AI super-resolution pipeline without manual configuration!\n",
        "\n",
        "## What it does:\n",
        "\n",
        "1. **Extracts job parameters** from URL (zero manual input needed!)\n",
        "2. **Downloads S2DR3 model** from Hugging Face\n",
        "3. **Runs 10m ‚Üí 1m super-resolution** using deep learning\n",
        "4. **Clips to your farm boundary** for precise results\n",
        "5. **Uploads results back to DHARTI** automatically\n",
        "\n",
        "## How to use:\n",
        "\n",
        "1. Click **\"Runtime\" ‚Üí \"Run all\"** (or press `Ctrl+F9` / `Cmd+F9`)\n",
        "2. Wait 3-5 minutes for processing\n",
        "3. Results appear automatically in DHARTI!\n",
        "\n",
        "> **No configuration needed!** All parameters are extracted from the URL when opened from DHARTI.\n",
        "\n",
        "---\n",
        "\n",
        "## Processing Time\n",
        "\n",
        "- **With GPU (T4)**: ~3 minutes ‚ö°\n",
        "- **CPU only**: ~8-10 minutes üê¢\n",
        "\n",
        "üí° **Tip**: Go to \"Runtime\" ‚Üí \"Change runtime type\" ‚Üí Select \"T4 GPU\" for faster processing!\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-g1mklUxcDZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 1. AUTO-EXTRACT PARAMETERS FROM URL (ZERO-CLICK CONFIGURATION)\n",
        "# ============================================================================\n",
        "import re\n",
        "import time\n",
        "from IPython.display import HTML, Javascript, display\n",
        "\n",
        "# Try to extract from URL fragment (e.g., #job_id=abc123&api_base=http://...)\n",
        "print(\"üîç Extracting configuration from URL...\")\n",
        "\n",
        "# Use JavaScript to extract parameters from URL hash\n",
        "display(Javascript(\"\"\"\n",
        "    // Extract parameters from URL fragment\n",
        "    const fragment = window.location.hash.substring(1); // Remove '#'\n",
        "    const params = new URLSearchParams(fragment);\n",
        "\n",
        "    const job_id = params.get('job_id') || '';\n",
        "    const api_base = params.get('api_base') || 'http://localhost:5000';\n",
        "\n",
        "    // Store in notebook metadata so Python can access\n",
        "    if (typeof IPython !== 'undefined' && IPython.notebook) {\n",
        "        IPython.notebook.metadata.job_id = job_id;\n",
        "        IPython.notebook.metadata.api_base = api_base;\n",
        "        console.log('‚úÖ Extracted job_id:', job_id);\n",
        "        console.log('‚úÖ Extracted api_base:', api_base);\n",
        "\n",
        "        // Update the cell output\n",
        "        const kernel = IPython.notebook.kernel;\n",
        "        kernel.execute(`job_id = \"${job_id}\"; api_base = \"${api_base}\"`);\n",
        "    }\n",
        "\"\"\"))\n",
        "\n",
        "# Wait for JavaScript to execute\n",
        "time.sleep(1)\n",
        "\n",
        "# Fallback: try to parse from URL using Python\n",
        "job_id = \"\"\n",
        "api_base = \"http://localhost:5000\"\n",
        "\n",
        "# If JavaScript didn't set it, try manual input\n",
        "if not job_id:\n",
        "    print(\"‚ö†Ô∏è  Could not auto-extract job_id from URL.\")\n",
        "    print(\"üìã Please copy the job_id from the DHARTI URL and paste below:\")\n",
        "    print(\"    (Look for: #job_id=YOUR_JOB_ID_HERE)\")\n",
        "    print()\n",
        "    job_id = input(\"Paste job_id here: \").strip()\n",
        "\n",
        "    if not job_id:\n",
        "        raise ValueError(\"‚ùå job_id is required! Please run the cell again and paste your job_id.\")\n",
        "\n",
        "    # Ask for API base if needed\n",
        "    custom_api = input(f\"API base URL (press Enter for {api_base}): \").strip()\n",
        "    if custom_api:\n",
        "        api_base = custom_api\n",
        "\n",
        "print(f\"\\n‚úÖ Configuration loaded:\")\n",
        "print(f\"   Job ID: {job_id}\")\n",
        "print(f\"   API Base: {api_base}\")\n",
        "print(f\"\\nüöÄ Proceeding with automated processing...\")\n",
        "print(f\"   (This will take 3-5 minutes)\\n\")\n"
      ],
      "metadata": {
        "id": "ml9MwhQ7cWUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 2. FETCH JOB PARAMETERS FROM DHARTI\n",
        "# ============================================================================\n",
        "import requests\n",
        "import json\n",
        "\n",
        "if not job_id:\n",
        "    raise ValueError(\"‚ùå Job ID not set! Please fill in the configuration cell above.\")\n",
        "\n",
        "print(\"üì° Fetching job parameters...\")\n",
        "response = requests.get(f\"{api_base}/api/s2dr3/jobs/{job_id}\")\n",
        "\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"‚ùå Failed to fetch job: {response.text}\")\n",
        "\n",
        "job = response.json()\n",
        "\n",
        "lon = job['lon']\n",
        "lat = job['lat']\n",
        "date = job['date']\n",
        "farm = job['farm']\n",
        "upload_token = job.get('upload_token', job_id)  # Fallback to job_id\n",
        "\n",
        "print(f\"‚úÖ Job loaded successfully!\")\n",
        "print(f\"   üìç Location: ({lat:.4f}, {lon:.4f})\")\n",
        "print(f\"   üìÖ Date: {date}\")\n",
        "print(f\"   üîí Upload token: {upload_token[:8]}...\")\n",
        "print()\n"
      ],
      "metadata": {
        "id": "hqvQy2tnYuMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üõ†Ô∏è Step 2: Install S2DR3 Wheel\n",
        "import subprocess\n",
        "\n",
        "wheel_url = \"https://storage.googleapis.com/0x7ff601307fa5/s2dr3-20250905.1-cp312-cp312-linux_x86_64.whl\"\n",
        "\n",
        "print(\"üì¶ Installing S2DR3 (Gamma Earth)...\")\n",
        "print(\"   This may take 1-2 minutes...\\n\")\n",
        "\n",
        "!pip install -q {wheel_url}\n",
        "\n",
        "print(\"\\n‚úÖ S2DR3 installed successfully!\")"
      ],
      "metadata": {
        "id": "Oni_6hRLYuPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéØ Step 3: Run S2DR3 Super-Resolution\n",
        "import s2dr3.inferutils\n",
        "import pathlib\n",
        "\n",
        "print(\"üöÄ Running S2DR3 inference...\")\n",
        "print(f\"   üìç Target: ({lat:.4f}, {lon:.4f})\")\n",
        "print(f\"   üìÖ Date: {date}\")\n",
        "print(\"   ‚è±Ô∏è  This will take 2-4 minutes...\\n\")\n",
        "\n",
        "# Run S2DR3\n",
        "lonlat = (lon, lat)\n",
        "s2dr3.inferutils.test(lonlat, date)\n",
        "\n",
        "# Find output files\n",
        "output_dir = pathlib.Path(\"/content/output\")\n",
        "output_files = list(output_dir.glob(\"*.tif\"))\n",
        "\n",
        "print(f\"\\n‚úÖ S2DR3 complete! Generated {len(output_files)} files:\")\n",
        "for f in output_files:\n",
        "    size_mb = f.stat().st_size / 1024 / 1024\n",
        "    print(f\"   üìÑ {f.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "# Identify products\n",
        "ms_file = next((f for f in output_files if \"_MS.tif\" in f.name), None)\n",
        "ndvi_file = next((f for f in output_files if \"_NDVI.tif\" in f.name), None)\n",
        "tci_file = next((f for f in output_files if \"_TCI.tif\" in f.name), None)\n",
        "irp_file = next((f for f in output_files if \"_IRP.tif\" in f.name), None)\n",
        "\n",
        "if not ms_file or not ndvi_file:\n",
        "    raise Exception(\"‚ùå Missing required outputs (MS or NDVI)\")"
      ],
      "metadata": {
        "id": "q5a0v1mfZDn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚úÇÔ∏è Step 4: Clip to Farm Boundary (Optional)\n",
        "# Install rasterio for clipping\n",
        "!pip install -q rasterio\n",
        "\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "import json\n",
        "\n",
        "print(\"‚úÇÔ∏è  Clipping images to farm boundary...\\n\")\n",
        "\n",
        "def clip_to_farm(in_file, out_file, farm_geom):\n",
        "    \"\"\"Clip a GeoTIFF to farm boundary\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(in_file) as src:\n",
        "            # Extract geometry\n",
        "            if farm_geom['type'] == 'Feature':\n",
        "                geom = farm_geom['geometry']\n",
        "            else:\n",
        "                geom = farm_geom\n",
        "\n",
        "            # Clip\n",
        "            out_image, out_transform = mask(src, [geom], crop=True, all_touched=True)\n",
        "            out_meta = src.meta.copy()\n",
        "\n",
        "            # Update metadata\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": out_image.shape[1],\n",
        "                \"width\": out_image.shape[2],\n",
        "                \"transform\": out_transform,\n",
        "                \"compress\": \"deflate\"\n",
        "            })\n",
        "\n",
        "            # Write\n",
        "            with rasterio.open(out_file, \"w\", **out_meta) as dest:\n",
        "                dest.write(out_image)\n",
        "                # Copy colormap if exists\n",
        "                if src.colormap(1):\n",
        "                    dest.write_colormap(1, src.colormap(1))\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è  Clipping failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Create clipped directory\n",
        "clipped_dir = pathlib.Path(\"/content/clipped\")\n",
        "clipped_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Clip each file\n",
        "clipped_files = {}\n",
        "\n",
        "if ms_file:\n",
        "    out_ms = clipped_dir / \"ms_clipped.tif\"\n",
        "    if clip_to_farm(ms_file, out_ms, farm):\n",
        "        clipped_files['ms'] = out_ms\n",
        "        print(f\"   ‚úÖ MS clipped\")\n",
        "\n",
        "if ndvi_file:\n",
        "    out_ndvi = clipped_dir / \"ndvi_clipped.tif\"\n",
        "    if clip_to_farm(ndvi_file, out_ndvi, farm):\n",
        "        clipped_files['ndvi'] = out_ndvi\n",
        "        print(f\"   ‚úÖ NDVI clipped\")\n",
        "\n",
        "if tci_file:\n",
        "    out_tci = clipped_dir / \"tci_clipped.tif\"\n",
        "    if clip_to_farm(tci_file, out_tci, farm):\n",
        "        clipped_files['tci'] = out_tci\n",
        "        print(f\"   ‚úÖ TCI clipped\")\n",
        "\n",
        "print(f\"\\n‚úÖ Clipped {len(clipped_files)} images to farm boundary\")"
      ],
      "metadata": {
        "id": "68GIz8i-ZJnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üì§ Step 5: Upload to DHARTI\n",
        "import requests\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(\"üì§ Uploading enhanced images to DHARTI...\\n\")\n",
        "\n",
        "upload_url = f\"{api_base}/api/s2dr3/jobs/{job_id}/upload\"\n",
        "headers = {\"Authorization\": f\"Bearer {upload_token}\"}\n",
        "\n",
        "# Prepare files for upload\n",
        "files_to_upload = {}\n",
        "\n",
        "if 'ms' in clipped_files:\n",
        "    files_to_upload['ms'] = ('ms.tif', open(clipped_files['ms'], 'rb'), 'image/tiff')\n",
        "    print(f\"   üì¶ MS (multispectral) ready...\")\n",
        "\n",
        "if 'ndvi' in clipped_files:\n",
        "    files_to_upload['ndvi'] = ('ndvi.tif', open(clipped_files['ndvi'], 'rb'), 'image/tiff')\n",
        "    print(f\"   üì¶ NDVI ready...\")\n",
        "\n",
        "if 'tci' in clipped_files:\n",
        "    files_to_upload['tci'] = ('tci.tif', open(clipped_files['tci'], 'rb'), 'image/tiff')\n",
        "    print(f\"   üì¶ TCI (true color) ready...\")\n",
        "\n",
        "# Upload with progress bar\n",
        "print(f\"\\n‚è≥ Uploading to {upload_url}...\")\n",
        "\n",
        "try:\n",
        "    response = requests.post(upload_url, headers=headers, files=files_to_upload, timeout=300)\n",
        "\n",
        "    # Close file handles\n",
        "    for _, (_, f, _) in files_to_upload.items():\n",
        "        f.close()\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(f\"\\n‚úÖ Upload successful!\")\n",
        "        print(f\"   üìä Status: {result.get('status', 'unknown')}\")\n",
        "\n",
        "        saved_files = result.get('saved', {})\n",
        "        if saved_files:\n",
        "            print(f\"   üìÅ Saved files:\")\n",
        "            for key, path in saved_files.items():\n",
        "                print(f\"      ‚Ä¢ {key}: {path}\")\n",
        "\n",
        "        print(f\"\\nüéâ Your enhanced 1m images are now available in DHARTI!\")\n",
        "        print(f\"   üîÑ Refresh your browser to see the super-resolved layer.\")\n",
        "        print(f\"   üó∫Ô∏è  It will appear as: 'NDVI (S2DR3 1m, AI-enhanced)'\")\n",
        "\n",
        "    elif response.status_code == 403:\n",
        "        print(f\"\\n‚ùå Upload denied: Invalid authentication token\")\n",
        "        print(f\"   This job may have expired or the token is incorrect.\")\n",
        "\n",
        "    elif response.status_code == 404:\n",
        "        print(f\"\\n‚ùå Job not found: {job_id}\")\n",
        "        print(f\"   The job may have been deleted or doesn't exist.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Upload failed: HTTP {response.status_code}\")\n",
        "        print(f\"   Response: {response.text[:200]}\")\n",
        "\n",
        "except requests.exceptions.Timeout:\n",
        "    print(f\"\\n‚è±Ô∏è  Upload timeout (>5 minutes)\")\n",
        "    print(f\"   Your files may still be uploading. Check DHARTI status.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Upload error: {e}\")\n",
        "    print(f\"\\nüí° You can manually download the files from /content/clipped/\")\n",
        "    print(f\"   Then contact support to upload them manually.\")"
      ],
      "metadata": {
        "id": "ElG-p4ygZRHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Pipeline Complete!\n",
        "\n",
        "The S2DR3 super-resolution has been successfully applied to your satellite imagery!\n",
        "\n",
        "### What was processed:\n",
        "\n",
        "- **Input**: Sentinel-2 10m resolution\n",
        "- **Output**: AI-enhanced 1m resolution (10x improvement!)\n",
        "- **Layers**: RGB (TCI), NDVI, Multi-spectral (10 bands)\n",
        "- **Processing Time**: ~3-5 minutes on GPU\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "1. **Return to DHARTI** web interface\n",
        "2. The modal will **automatically refresh** and show your enhanced images\n",
        "3. Use the **RGB/NDVI toggle** to switch between visualizations\n",
        "4. **Download** high-resolution GeoTIFFs if needed\n",
        "\n",
        "### Technical Details\n",
        "\n",
        "- **Model**: S2DR3 (Sentinel-2 Deep Residual Refine & Restore)\n",
        "- **Resolution**: 10x super-resolution (10m ‚Üí 1m)\n",
        "- **Architecture**: ResNet-based deep learning model\n",
        "- **Output Format**: GeoTIFF with proper georeferencing\n",
        "- **CRS**: EPSG:4326 (WGS84)\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "If you don't see the images in DHARTI:\n",
        "\n",
        "1. Check that the upload completed successfully (green ‚úÖ above)\n",
        "2. Refresh the DHARTI page\n",
        "3. Check browser console for errors\n",
        "4. Verify the job_id matches what you clicked in DHARTI\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Powered by DHARTI + S2DR3**\n",
        "\n",
        "*This automated pipeline brings professional-grade AI super-resolution to agricultural satellite imagery!*\n"
      ],
      "metadata": {
        "id": "UiHkfap8c9R1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7agNXmSpc6V8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}